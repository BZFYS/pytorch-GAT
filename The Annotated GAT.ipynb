{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Annotated GAT\n",
    "\n",
    "The idea of this notebook is to make it easier even for non-researchers to understand the Graph Attention Network (and GNNs in general)!\n",
    "\n",
    "In this notebook you'll get answers to there questions:\n",
    "\n",
    "‚úÖ What is GAT exactly? <br/>\n",
    "‚úÖ How to train it? <br/>\n",
    "‚úÖ How to use it (Cora classification example)? <br/>\n",
    "\n",
    "After you complete this one you'll have a much better understanding of graph neural networks in general!\n",
    "\n",
    "*Note: Cora is a transductive setting, I'll be adding an inductive example soon as well (PPI - protein protein interaction, probably).*\n",
    "\n",
    "Nice, let's start!\n",
    "\n",
    "---\n",
    "\n",
    "## What the heck are Graph Attention Networks?\n",
    "\n",
    "Graph Attention Network, or GAT for short, is a Graph Neural Network (GNN) published by `Veliƒçkoviƒá et al.` in a paper called [Graph Attention Networks](https://arxiv.org/abs/1710.10903) back in 2017.\n",
    "\n",
    "It turns out that combining the idea of **attention** with the already existing **graphs convolutional networks** (GCN) was a good move ü§ì - GAT is the **2nd most cited** paper in the GNN literature (as of the time of writing this).\n",
    "\n",
    "So because `GCN + attention = GAT` in order to understand GAT you basically need to understand GCNs.\n",
    "\n",
    "The whole idea came from CNNs (*stack push GCN (a nervous chuckle)*). Convolutional Neural Networks were working so nicely, solving various computer vision tasks and creating a huge hype in the world of deep learning, so some folks decided to transfer the idea onto graphs.\n",
    "\n",
    "The basic problem is that while the image lies on a regular grid (which you can also treat as a graph (*sighs*)), and thus has a precise notion of **order** (e.g. my **top-left** neighboor (*popularly known as pixels in the CV world*)), graphs don't enjoy that nice property and both the number of neighbors as well as the order of neighbors may vary. \n",
    "\n",
    "How can you define a kernel for a graph? The kernel size can't be `3x3` because sometimes a node will have 2 neighbors and sometimes 233240 (*breaks the keyboard*).\n",
    "\n",
    "2 main ideas popped up:\n",
    "* **spectral methods** (they all somehow leverage the graph Laplacian eigenbasis (I'll completely ignore them here))\n",
    "* **spatial methods** \n",
    "\n",
    "Although spatial methods can vaguely be motivated by the spectral ones it's much more healthy to think of them directly from the spatial perspective. Ok, here it goes. (*stack pop GCN*)\n",
    "\n",
    "---\n",
    "\n",
    "**High level explanation of spatial (message passing) methods:** \n",
    "\n",
    "So you have the feature vectors from your neighbors at your disposal. You do the following:\n",
    "\n",
    "1. You somehow transform them (maybe a linear projection)\n",
    "2. You somehow aggregate them (maybe weighing them with attention coefficients, voil√†, we get GAT (*you see what I did there*))\n",
    "3. You update the feature vector (somehow) of the current node by combining it's (transformed) feature vector with the aggregated neighborhood representation.\n",
    "\n",
    "And that's pretty much it, you can fit many different GNNs into this framework.\n",
    "\n",
    "Here is how GAT schematic looks like (those differently colored edges represent different attention heads):\n",
    "\n",
    "<img src=\"data/readme_pics/GAT_schematic.PNG\" alt=\"transformer architecture\" align=\"center\" style=\"width: 600px;\"/> <br/>\n",
    "\n",
    "**Fun fact:** *transformers* can be thought of as a special case of *GAT* - when the input graph is **fully-connected**. Check out [this blog](https://thegradient.pub/transformers-are-graph-neural-networks/) for more details.\n",
    "\n",
    "---\n",
    "\n",
    "That was everything you need to know for now! <br/>\n",
    "\n",
    "If you need further help understanding all of the details I created this [in-depth overview of the GAT paper:](https://www.youtube.com/watch?v=uFLeKkXWq2c)\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=uFLeKkXWq2c\" target=\"_blank\"><img src=\"https://img.youtube.com/vi/uFLeKkXWq2c/0.jpg\" \n",
    "alt=\"An in-depth overview of the Graph Attention Networks\" width=\"480\" align=\"left\" height=\"360\" border=\"10\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
